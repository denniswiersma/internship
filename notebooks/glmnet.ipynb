{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458f5f39",
   "metadata": {},
   "source": [
    "# GLMNET\n",
    "\n",
    "## set working directory\n",
    "Warning: only run the cell below once per kernel session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb240c64f15c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f50762da255de7",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import tomllib\n",
    "\n",
    "with open(\"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "data = Data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027add39",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f5a1aea3c4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new mixing matrix has different sample separator\n",
    "data.replace_sample_sep(\".\")\n",
    "# filter the tumor types for those which have more than x samples\n",
    "data.filter_tt(100)\n",
    "# check how many unique tumor types are left\n",
    "unique_tt = data.tumor_types[\"response\"].unique()\n",
    "print(\"Number of tumor types:\", len(unique_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8076e8dae4887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the current state of the data with a tumor types column\n",
    "dataset = data.get_mm_with_tt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3937c0ac4f44157",
   "metadata": {},
   "source": [
    "## Optional: subset\n",
    "\n",
    "Choose one of the cells below, or make your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3668cab2982bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data.subset(dataset, n_rows=8510, n_cols=9709, n_labels=12)  # Does not guarantee an equal number of samples per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16375623f71094b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data.subset_nrows_per_label(dataset, nrows_per_label=32, ncols=9709, nlabels=len(unique_tt))  # Guarantees an equal number of samples per label, use all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3054e05b58110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data.subset_nrows_per_label(dataset, nrows_per_label=30, ncols=9709, nlabels=22)  # Guarantees an equal number of samples per label, use x labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c4545578c329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb100639b07cad",
   "metadata": {},
   "source": [
    "## Optional: aggregate labels\n",
    "The cell below is only necessary when you want to aggregate some of the labels into one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acf973fe693870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the all the labels from the 12th onward into one label\n",
    "labels_to_replace = unique_tt[11:]\n",
    "dataset[\"response\"] = dataset[\"response\"].replace(labels_to_replace, \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ef04b76b5c401",
   "metadata": {},
   "source": [
    "## Split train, test, val\n",
    "Split the data into train, test, and validation sets.\n",
    "Choose either of the two cells below printing the dataset's size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fff7fc587c23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size of dataset:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce9b2390007ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sizes of the train, test, and validation sets according to some fraction\n",
    "train, test, val = data.get_train_test_val(\n",
    "    train_size=0.7,\n",
    "    test_size=0.2,\n",
    "    val_size=0.1,\n",
    "    data=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a38642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the subset as training data and the rest as test\n",
    "# WARNING: do not run the `dataset = subset` cell in the `subset` section if you want to use this cell\n",
    "unique_subset_tt = subset[\"response\"].unique()\n",
    "\n",
    "filtered_dataset = dataset[dataset[\"response\"].isin(unique_subset_tt)]\n",
    "\n",
    "is_train = filtered_dataset.index.isin(subset.index)\n",
    "train = filtered_dataset[is_train]\n",
    "test = filtered_dataset[~is_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a3f4e3dd2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes and distributions of the train, test, and validation sets\n",
    "print(\"size of train:\", train.shape)\n",
    "print(\"size of test:\", test.shape)\n",
    "# print(\"size of val:\", val.shape)\n",
    "\n",
    "from ml.glm import GLM\n",
    "glm = GLM(data)\n",
    "# _, _ = glm.plot_label_distribution(train, test, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce187f3dacf1908d",
   "metadata": {},
   "source": [
    "## Split reponse from predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4db41c4d5f37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = data.split_xy(train)\n",
    "xtest, ytest = data.split_xy(test)\n",
    "# xval, yval = data.split_xy(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154b20",
   "metadata": {},
   "source": [
    "## Run GLMNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "glm.fit(xtrain, ytrain, alpha=0)\n",
    "\n",
    "end = datetime.now()\n",
    "print(end)\n",
    "print(\"duration:\", end - start)\n",
    "\n",
    "glm.plot()\n",
    "glm.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd65d2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89478183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ypredict = glm.predict(newx=xtest, type=\"class\")\n",
    "ypredict_probs = glm.predict(newx=xtest, type=\"response\")\n",
    "ypredict_probs = np.squeeze(ypredict_probs, axis=-1) # method above returns 3D array where 3rd dimension is 1. We remove it here to get a 2D array to pass to the assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bc56e9b082ace",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd4a84f13a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.assess(ytest, ypredict, ypredict_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
