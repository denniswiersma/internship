{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a9ec08fa388777",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Cforest\n",
    "This notebook is used to fit cforest models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83def0ec-db46-4c3a-9d58-105c7a9bb015",
   "metadata": {},
   "source": [
    "## Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7c88254484070c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/dwiersma/Desktop/internship\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f2b5d-4051-487f-a6f2-65c196ab5abb",
   "metadata": {},
   "source": [
    "## Load data\n",
    "One can choose one of three options for loading data:\n",
    "- load the GPL570 dataset (assumes you have set the appropriate parameters in `config.toml`)\n",
    "- load the tcga dataset (change `config` parameters on the fly. Set correctly in it's cell)\n",
    "- load a subset created with the `datasets.ipynb` notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fa7d5a-ef5f-4b9d-bc1f-30321cbe401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "from src.data import Data\n",
    "\n",
    "# load config\n",
    "with open(\"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537427fe-5d82-4d8a-aff6-743b09ce75fd",
   "metadata": {},
   "source": [
    "### Load GPL570 microarray data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455201e3-413e-4078-8c01-986df346af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 16:44:44,241:src.log_manager:INFO:Loading data...\n",
      "2024-01-25 16:46:45,664:src.log_manager:INFO:Data loaded in 121.4209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixing matrix shape: (15403, 9709)\n",
      "ma_data shape: (15403, 9710)\n"
     ]
    }
   ],
   "source": [
    "# load the microarray data (set in config.toml)\n",
    "data = Data(config)\n",
    "\n",
    "ma_data = data.get_mm_with_tt()\n",
    "# replace the spaces in the covariate's names with underscores\n",
    "ma_data.columns = ma_data.columns.str.replace(\" \", \"_\")\n",
    "print(f\"mixing matrix shape: {data.mixing_matrix.shape}\")\n",
    "print(f\"ma_data shape: {ma_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e16e42-7e2f-478d-8682-3cde4b67f3a3",
   "metadata": {},
   "source": [
    "### Load TCGA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174bbe3-4646-46bb-b44b-980315bf0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data location to the TCGA mixing matrix\n",
    "config[\"data\"][\"locations\"][\"mixing_matrix\"] = \"data/corrected_mixing_matrix.tsv\"\n",
    "config[\"data\"][\"locations\"][\"tumor_types\"] = \"data/TCGA__Sample_To_TumorType_with_common_cancer_type_mapping_GEO_TCGA.tsv\"\n",
    "\n",
    "# set correct column names for the annotation data\n",
    "config[\"data\"][\"columns\"][\"tumor_types\"][\"sample_name\"] = \"ID2\"\n",
    "config[\"data\"][\"columns\"][\"tumor_types\"][\"response\"] = \"TYPE3\"\n",
    "\n",
    "# load the tcga data\n",
    "data = Data(config)\n",
    "\n",
    "# replaces the \"-\" in sample names with \".\" to match the sample names in the mixing matrix and annotation data\n",
    "data.replace_sample_sep(\".\")\n",
    "\n",
    "# fetch a joined dataset with mixing matrix weights and the respective cancer type annotations\n",
    "tcga_data = data.get_mm_with_tt()\n",
    "# replace the spaces in the covariate's names with underscores\n",
    "tcga_data.columns = tcga_data.columns.str.replace(\" \", \"_\")\n",
    "print(f\"mixing matrix shape: {data.mixing_matrix.shape}\")\n",
    "print(f\"tcga_data shape: {tcga_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8e1949629dbd1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load subsetted data\n",
    "\n",
    "Since the subsets have already gone through the datapipeline in `datasets.ipynb`, a lot less configuring and changing is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c2436-fc57-417f-8f52-ca90e147c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# unfortunately, we have to load a dataset through the pipeline because the Cforest class expects a data object.\n",
    "# the data in this object will not be the data used to fit the model. That data is passed to the `fit` funtion.\n",
    "data = Data(config)\n",
    "\n",
    "subset = pd.read_csv(\"data/subsets_sorted/tcga_15ct_min100s.csv\", index_col=\"samples\")\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800a4b20c404484",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Split data into train, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66996a341e9a171f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the sizes of the train, test, and validation sets according to some fraction\n",
    "train, test, val = data.get_train_test_val(\n",
    "    train_size=0.7,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
<<<<<<< Updated upstream
    "    data=dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66996a341e9a171f"
=======
    "    data=tcga_data\n",
    ")\n",
    "\n",
    "# save the testset to disk for later use\n",
    "test.to_csv(Path(config[\"output\"][\"locations\"][\"cforest\"]).parent.joinpath(\"test_data\").with_suffix(\".csv\"))"
   ]
>>>>>>> Stashed changes
  },
  {
   "cell_type": "markdown",
   "id": "fdf013749bc60464",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Build the cforest model\n",
    "\n",
    "The plot, save, and assess methods will save files to the output directory specified in the `config.toml` file.\n",
    "Each model type (e.g., glm, ctree, cforest) has its own output directory.\n",
    "Each model fit will have its own subdirectory in the model type directory consisting of the date, time, and a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0093d2b0c9330",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from src.ml.cforest import Cforest\n",
    "cforest = Cforest(data)\n",
    "\n",
<<<<<<< Updated upstream
    "ctrl = cforest.CtreeControl(\n",
    "    testtype= \"Univariate\",\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "cforest.fit(\n",
    "    train=train,\n",
    "    ctree_control=ctrl,\n",
    "    ntree=10,\n",
    "    cores=config[\"execution\"][\"cores\"]\n",
    ")\n",
    "\n",
    "cforest.save()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea0093d2b0c9330"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ypredict_probs = cforest.predict(newx=test.drop(columns=[\"response\"]), type=\"prob\")\n",
    "ypredict = cforest.predict(newx=test.drop(columns=[\"response\"]), type=\"response\")\n",
    "\n",
    "cforest.assess(ytrue=test[\"response\"], ypredict=ypredict, ypredict_probs=ypredict_probs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a691e7a5214cf99e"
=======
    "# whether to run the predict block\n",
    "predict = True\n",
    "# which data to use to fit the model\n",
    "dataset = train\n",
    "\n",
    "# Grid search parameters\n",
    "ntrees = [50]\n",
    "testtype = [\"Univariate\"]\n",
    "minsplit = [20]\n",
    "minbucket = [14]\n",
    "\n",
    "# create a list of all parameter combinations to run\n",
    "options = itertools.product(ntrees, testtype, minsplit, minbucket)\n",
    "\n",
    "for option in options:\n",
    "    ctrl = cforest.CtreeControl(\n",
    "        testtype=option[1],\n",
    "        minsplit=option[2],\n",
    "        minbucket=option[3],\n",
    "    )\n",
    "\n",
    "    cforest.fit(\n",
    "        train=dataset,\n",
    "        ctree_control=ctrl,\n",
    "        ntree=option[0],\n",
    "        cores=config[\"execution\"][\"cores\"]\n",
    "    )\n",
    "\n",
    "    cforest.save()\n",
    "    \n",
    "    if predict:\n",
    "        ## Predict on train ##\n",
    "        ypredict_probs = cforest.predict(newx=train.drop(columns=[\"response\"]), type=\"prob\")\n",
    "        ypredict = cforest.predict(newx=train.drop(columns=[\"response\"]), type=\"response\")\n",
    "        cforest.assess(ytrue=train[\"response\"], ypredict=ypredict, ypredict_probs=ypredict_probs, name=\"clustermap_train\")\n",
    "        \n",
    "        ## Predict on val ##\n",
    "        ypredict_probs = cforest.predict(newx=val.drop(columns=[\"response\"]), type=\"prob\")\n",
    "        ypredict = cforest.predict(newx=val.drop(columns=[\"response\"]), type=\"response\")\n",
    "        cforest.assess(ytrue=val[\"response\"], ypredict=ypredict, ypredict_probs=ypredict_probs, name=\"clustermap_val\")"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
