{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458f5f39",
   "metadata": {},
   "source": [
    "# GLMNET\n",
    "\n",
    "## set working directory\n",
    "Warning: only run the cell below once per kernel session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb240c64f15c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f50762da255de7",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import tomllib\n",
    "\n",
    "with open(\"config.toml\", \"rb\") as file:\n",
    "    config = tomllib.load(file)\n",
    "\n",
    "data = Data(config)\n",
    "\n",
    "# postprocess data\n",
    "data.replace_sample_sep(\".\")\n",
    "data.filter_tt(100)\n",
    "unique_tt = data.tumor_types[\"response\"].unique()\n",
    "print(\"Number of tumor types:\", len(unique_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027add39",
   "metadata": {},
   "source": [
    "## Setup for GLMNET\n",
    "\n",
    "Note: the amount of data in the subset might differ from the amount requested in `data.get_subset()`, when you request more data than the given number of labels can provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f5a1aea3c4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.get_mm_with_tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3054e05b58110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: subset\n",
    "# dataset = data.subset(dataset, n_rows=250, n_cols=9709, n_labels=15)  # Does not guarantee an equal number of samples per label\n",
    "# dataset = data.subset_nrows_per_label(dataset, nrows_per_label=100, ncols=9709, nlabels=len(unique_tt))  # Guarantees an equal number of samples per label, use all labels\n",
    "dataset = data.subset_nrows_per_label(dataset, nrows_per_label=100, ncols=9709, nlabels=12)  # Guarantees an equal number of samples per label, use x labels"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below is only necessary when you want to aggregate some of the labels into one label."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ffb100639b07cad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# aggregate the all the labels from the 12th onward into one label\n",
    "labels_to_replace = unique_tt[11:]\n",
    "dataset[\"response\"] = dataset[\"response\"].replace(labels_to_replace, \"other\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78acf973fe693870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a38642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.glm import GLM\n",
    "glm = GLM(data)\n",
    "\n",
    "print(\"size of dataset:\", dataset.shape)\n",
    "\n",
    "train, test, val = data.get_train_test_val(\n",
    "    train_size=0.7,\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    "    data=dataset\n",
    ")\n",
    "\n",
    "print(\"size of train:\", train.shape)\n",
    "print(\"size of test:\", test.shape)\n",
    "print(\"size of val:\", val.shape)\n",
    "\n",
    "_, _ = glm.plot_label_distribution(train, test, val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce187f3dacf1908d",
   "metadata": {},
   "source": [
    "## Split reponse from predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4db41c4d5f37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = data.split_xy(train)\n",
    "xtest, ytest = data.split_xy(test)\n",
    "xval, yval = data.split_xy(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154b20",
   "metadata": {},
   "source": [
    "## Run GLMNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "print(start)\n",
    "\n",
    "fit = glm.fit(xtrain, ytrain, alpha=0, maxit=1e6)\n",
    "\n",
    "end = datetime.now()\n",
    "print(end)\n",
    "print(\"duration:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd65d2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89478183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ypredict = glm.predict(fit, newx=xtest, type=\"class\")\n",
    "ypredict_probs = glm.predict(fit, newx=xtest, type=\"response\")\n",
    "ypredict_probs = np.squeeze(ypredict_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bc56e9b082ace",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd4a84f13a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.assess(ytest, ypredict, ypredict_probs)\n",
    "glm.assess_cm(ypredict_probs, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
